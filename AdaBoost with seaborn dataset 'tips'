# AdaBoost with seaborn dataset 'tips'
# ML, classification: predicting which day people had their meals from other data provided

# SUMMARY - need a larger dataset to apply adaptive boosting

import sklearn
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score 
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC

import pandas
from pandas import concat

import seaborn as sns

df = sns.load_dataset("tips")


df2 = df[["sex", "smoker", "day", "time"]]                              # Filter by categorical variables only

df2["day"].value_counts()                                               # The target variable is not even - drop Friday and sample Thur, Sat, Sun

print(df2.iloc[90:102, :])                                              # 19 instances of Friday
print(df2.iloc[220:227, :])

df3 = df2[df2.day != "Fri"]                                             # Removes all Fri

for i in df3.day:                                                       # Simple check - no Fri                        
    if i == "Fri":
        print(i)
        
Thur = df3[df3["day"] == "Thur"]                                        # Split dfs
Sat = df3[df3["day"] == "Sat"]
Sun = df3[df3["day"] == "Sun"]

Thur_sample = Thur.sample(n = 50)                                       # Sample 50 randomly from each day
Sat_sample = Sat.sample(n = 50)
Sun_sample = Sun.sample(n = 50)

df4 = concat([Thur_sample, Sat_sample, Sun_sample])

df4 = df4.reset_index(drop = True)

df4["day"].value_counts()                                               # Sampled dataframe - 50 each for Thur, Sat, Sun and no Fri

df4                                                                     # Target variable now even

df5 = df4.apply(LabelEncoder().fit_transform)                           # Female = 0, Male = 1, 
                                                                        # Non-smoker = 0, Smoker = 1
                                                                        # Sat = 0, Sun = 1, Thur = 2
                                                                        # Dinner = 0, Lunch = 1

df5                        

X = df5.drop("day", axis = 1)      
y = df5["day"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)

DTC = DecisionTreeClassifier()       
DTC.fit(X_train, y_train)

accuracy_score(y_test, DTC.predict(X_test))                             # 70% accurate with Decision Tree - now apply Adaboost

cm = confusion_matrix(y_test, DTC.predict(X_test))
cm                                                                      # Thur is predicted fine. Trouble is with the weekend.


ABC = AdaBoostClassifier(base_estimator = DTC, n_estimators = 500, learning_rate = 1, random_state = 42)

ABC.fit(X_train, y_train)

accuracy_score(y_test, ABC.predict(X_test))

cm = confusion_matrix(y_test, ABC.predict(X_test))                      
cm                                                                       # Accuracy scores are exactly the same - possible reasons: dataset is too small, need another base model


# Change weak learner to SVM

svm = SVC()
svm.fit(X_train, y_train)
accuracy_score(y_test, svm.predict(X_test)) 

ABC = AdaBoostClassifier(algorithm = 'SAMME', base_estimator = svm, n_estimators = 500, learning_rate = 1, random_state = 42)            # NB for svm use: algorithm = 'SAMME'

ABC.fit(X_train, y_train)

accuracy_score(y_test, ABC.predict(X_test))                              # Reduces accuracy - conclusion is that data set is too small for boosting


# Try using original df2 (unsampled)

df6 = df2.apply(LabelEncoder().fit_transform)            

X = df6.drop("day", axis = 1)      
y = df6["day"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)

DTC = DecisionTreeClassifier()       
DTC.fit(X_train, y_train)

accuracy_score(y_test, DTC.predict(X_test))                               # Accuracy = 0.7142857142857143

cm = confusion_matrix(y_test, DTC.predict(X_test))
cm                                                                        # 4x4 matrix - one target variable (Fri I think) wasn't even predicted with the decision tree


ABC = AdaBoostClassifier(base_estimator = DTC, n_estimators = 500, learning_rate = 1, random_state = 42)

accuracy_score(y_test, ABC.predict(X_test))                               # Accuracy reduced again 


# Conclusion - data set too small for Adaboost - I will commit another with a larger data set
