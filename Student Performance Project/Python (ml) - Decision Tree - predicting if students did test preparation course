# Students Performance in Exams (dataset from Kaggle)

# I do not own this dataset - I am simply doing some analysis on it, no copyright intended. Citation: 
# Author - Jakki Seshapanpu
# Original source - https://www.kaggle.com/spscientist/students-performance-in-exams


import pandas
from pandas import read_csv, concat

import sklearn
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix
from sklearn.model_selection import train_test_split

from matplotlib import pyplot as plt


df = read_csv("StudentsPerformance.csv")
df.isnull().sum() 


# There are a couple of ml problems available - regression problem with the test scores and classification problem with the test preparation course
# Start with classification - predicting if a student did the test preparation course (tpc) based on other four attributes


df2 = df[["gender", "race/ethnicity", "parental level of education", "lunch", "test preparation course"]]
df2

for i in df2.columns:
     print(df2[i].value_counts())    

# The target variable is not even - sample 300 of each - e.g. 300 completed and 300 'none'

completed = df2[df2["test preparation course"] == "completed"]
none = df2[df2["test preparation course"] == "none"]

completed_sample = completed.sample(n = 300)
none_sample = none.sample(n = 300)

df3 = concat([completed_sample, none_sample])              
df3 = df3.reset_index(drop = True)

print(df3["test preparation course"].value_counts())                           # tpc, none = 300, completed = 300

df3

df4 = df3.apply(LabelEncoder().fit_transform)                  
df4

X = df4.drop("test preparation course", axis = 1)      
y = df4["test preparation course"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)

DTC = DecisionTreeClassifier()       
DTC.fit(X_train, y_train)
accuracy_score(y_test, DTC.predict(X_test))

cm = confusion_matrix(y_test, DTC.predict(X_test))
cm

# array([[42, 20],
#       [31, 27]], dtype=int64)

DTC.predict(X_test)

l1 = []
l2 = []

for i in DTC.predict(X_test):
    if i == 0:
        l1.append(i)
    elif i == 1:
        l2.append(i)        

print(len(l1))
print(len(l2))

# e.g. model predicts 'completed' 73 times - 42 of these are correct, 31 incorrect
# model predicts 'none' 47 times - 27 of these are correct, 20 incorrect

tpc = ["completed", "none"]

plot_confusion_matrix(DTC, X_test, y_test, display_labels = tpc)
plt.show()

# Default decision tree is only 57.5% accurate - not really worth using.
