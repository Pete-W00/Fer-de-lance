# Students Performance in Exams (dataset from Kaggle)
# I do not own this dataset - I am simply doing some analysis on it, no copyright intended. Citation: 
# Author - Jakki Seshapanpu
# Original source - https://www.kaggle.com/spscientist/students-performance-in-exams


# Predicting if a student did the test preparation course (tpc) based on other four attributes - using Naive Bayes


import pandas
from pandas import read_csv, concat, DataFrame

import sklearn
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB

from matplotlib import pyplot as plt


df = read_csv("StudentsPerformance.csv")

df

df.isnull().sum() 

df2 = df[["gender", "race/ethnicity", "parental level of education", "lunch", "test preparation course"]]

df2

# The target variable is not even - sample 300 of each - e.g. 300 completed and 300 'none'

completed = df2[df2["test preparation course"] == "completed"]
none = df2[df2["test preparation course"] == "none"]

completed_sample = completed.sample(n = 300)
none_sample = none.sample(n = 300)

df3 = concat([completed_sample, none_sample])              
df3 = df3.reset_index(drop = True)

print(df3["test preparation course"].value_counts())                           # tpc, none = 300, completed = 300

df3

df4 = df3.apply(LabelEncoder().fit_transform)                  
df4

X = df4.drop("test preparation course", axis = 1)      
y = df4["test preparation course"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)

GNB = GaussianNB()
GNB.fit(X_train, y_train)
accuracy_score(y_test, GNB.predict(X_test))                                    # 50.8% accurate

cm = confusion_matrix(y_test, GNB.predict(X_test))
cm

tpc = ["completed", "none"]

plot_confusion_matrix(GNB, X_test, y_test, display_labels = tpc)
plt.title("GNB = GaussianNB()")
plt.show()

print(X_test)
print(y_test)

prediction_probabilities = GNB.predict_proba(X_test)       
prediction_probabilities 

# This is telling - none of the probabilities are near 0 or 1 (most are near parity - a bad sign - the model is sat on the fence with the decision making)

prediction_probabilities.round(1)     

# rounding shows how close each decision is - either 50/50 or at best 60/40 or 40/60 as to whether the test was completed or not                                      

# gender and race/ethnicity are probably unhelpful to estimate if the tpc was completed or not - drop these and reapply ml model

df5 = df4[["parental level of education", "lunch", "test preparation course"]]

df5

X = df5.drop("test preparation course", axis = 1)      
y = df5["test preparation course"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)

GNB = GaussianNB()
GNB.fit(X_train, y_train)
accuracy_score(y_test, GNB.predict(X_test))              # Accuracy now at 55.8% (dropping the unhelpful columns increased the accuracy)

prediction_probabilities = GNB.predict_proba(X_test)       
prediction_probabilities.round(2) 

plot_confusion_matrix(GNB, X_test, y_test, display_labels = tpc)
plt.title("GNB = GaussianNB()")
plt.show()


# There are only 12 combinations for the predictions, so it's possible to see all the outputs

print(df.lunch.nunique())                                # 2
print(df["parental level of education"].nunique())       # 6

print(GNB.predict([[0, 0]]))                 # associate's degree + free/reduced lunch = completed
print(GNB.predict([[1, 0]]))                 # bachelor's degree + free/reduced lunch = none
print(GNB.predict([[2, 0]]))                 # high school + free/reduced lunch = none
print(GNB.predict([[3, 0]]))                 # masters degree + free/reduced lunch = none
print(GNB.predict([[4, 0]]))                 # some college + free/reduced lunch = completed
print(GNB.predict([[5, 0]]))                 # some high school + free/reduced lunch = completed

print(GNB.predict([[0, 1]]))                 # associate's degree + standard lunch = none
print(GNB.predict([[1, 1]]))                 # bachelor's degree + standard lunch = none
print(GNB.predict([[2, 1]]))                 # high school + standard lunch = none
print(GNB.predict([[3, 1]]))                 # masters degree + standard lunch = none
print(GNB.predict([[4, 1]]))                 # some college + standard lunch = none
print(GNB.predict([[5, 1]]))                 # some high school + standard lunch = completed

# Hard to draw conclusions from this, having a standard lunch does not suggest that you took the tpc
# parental education = 'some high school' implies student completed the tpc (perhaps the tpc was based on this)
# Need more data.
